{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import telepot\n",
    "from telepot.loop import MessageLoop\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import threading\n",
    "import glob\n",
    "import re\n",
    "import traceback\n",
    "\n",
    "stock_predictor_bot = telepot.Bot('359528427:AAHKD8rIiFpo0ufZTDvLRGQ9c6gTfFFfYq4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.3.0\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.5.3 (default, Nov 23 2017 11:34:05)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "# logger = logging.getLogger()\n",
    "# logger.setLevel(logging.INFO)\n",
    "# from pyspark.sql import Row\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "sys.path.insert(0, spark_home + \"/python\")\n",
    "\n",
    "# Add the py4j to the path.\n",
    "# You may need to change the version number to match your install\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.6-src.zip'))\n",
    "\n",
    "# Initialize PySpark to predefine the SparkContext variable 'sc'\n",
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import GBTRegressionModel\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "days = 29\n",
    "gbtModel_30_features = PipelineModel.load('../gbtModel_30_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_float( x):\n",
    "    try:\n",
    "        x['Volume'] = float(x['Volume'])\n",
    "        x['Close'] = float(x['Close'])\n",
    "        x['High'] = float(x['High'])\n",
    "        x['Low'] = float(x['Low'])\n",
    "        x['Open'] = float(x['Open'])\n",
    "        return x\n",
    "    except:\n",
    "        x['Volume'] = float(x['Volume'])\n",
    "        x['Close'] = float(x['Close'])\n",
    "        x['High'] = float(x['Close'])\n",
    "        x['Low'] = float(x['Close'])\n",
    "        x['Open'] = float(x['Close'])\n",
    "        return x\n",
    "    \n",
    "def feature_ext(temp=None):\n",
    "    temp['close_close_gap'] = (temp['Close'].shift(-1) - temp['Close']) / temp['Close']\n",
    "    temp['close_open_gap'] = (temp['Open'].shift(-1) - temp['Close']) / temp['Close']\n",
    "    temp['close_high_gap'] = (temp['High'].shift(-1) - temp['Close']) / temp['Close']\n",
    "    temp['close_low_gap'] = (temp['Low'].shift(-1) - temp['Close']) / temp['Close']\n",
    "    temp.drop(labels=[\"High\",\"Low\",\"Open\",\"Close\"], axis=1,inplace=True)\n",
    "    return temp\n",
    "\n",
    "def get_features(daily_price_data, code, date_list, days_to_be_stacked) :\n",
    "    features = {}\n",
    "    print(\"date list \" + str(date_list))\n",
    "    for date in date_list :\n",
    "        try :\n",
    "            selected_index = daily_price_data.index[daily_price_data['Date'] == date].tolist()\n",
    "\n",
    "            if len(selected_index) == 0 :\n",
    "                print(\"date \" + date + \"is not found\")\n",
    "                continue\n",
    "\n",
    "            selected_index = selected_index[0]\n",
    "            df = daily_price_data[selected_index + 1 : selected_index + days_to_be_stacked + 2]\n",
    "            df = df.reset_index().drop('index',axis=1)\n",
    "            df = df.drop(labels=['Date'], axis=1)\n",
    "            df = df.apply(lambda x:convert_float(x),axis=1)\n",
    "            feature_ext(df)\n",
    "            df = df[0:days_to_be_stacked]\n",
    "            df = df.stack().to_frame().T\n",
    "            df.columns = ['{}_{}'.format(*c) for c in df.columns]\n",
    "#             features.append(df.values[0].tolist())\n",
    "            features[date] = df.values[0].tolist()\n",
    "        except Exception as e:\n",
    "            traceback.print_exc()\n",
    "            print(\"exception when get feature \" + str(e) + \" for date \" + date)\n",
    "    \n",
    "    return features\n",
    "\n",
    "def handle_message(msg):\n",
    "    print('updated 10')\n",
    "    content_type, chat_type, chat_id = telepot.glance(msg)\n",
    "\n",
    "    message = \"\"\n",
    "    username = msg[\"from\"][\"first_name\"]\n",
    "    if content_type == 'text':\n",
    "        message = msg[\"text\"]\n",
    "        if 'predict' in message :\n",
    "            message = message.split('predict')[1].lstrip()\n",
    "            data = message.split('\\n')\n",
    "            stock_code = data[0].lstrip()\n",
    "            date_list = data[1:]\n",
    "            stock_predictor_bot.sendMessage(chat_id, 'prediction starting.. ')\n",
    "            predict_stock(chat_id, stock_code, date_list)\n",
    "\n",
    "def predict_stock(chat_id, stock_code, date_list):\n",
    "    daily_price_data = []\n",
    "    try :\n",
    "        daily_price_data = pd.read_csv('../until31_2017/' + stock_code.lstrip() + '.csv')\n",
    "    except Exception as e:\n",
    "        stock_predictor_bot.sendMessage(chat_id, 'invalid stock name ')\n",
    "        print('invalid stock name ' + str(e))\n",
    "        return\n",
    "    \n",
    "    features = []\n",
    "    try :\n",
    "        stock_predictor_bot.sendMessage(chat_id, 'gathering features for stock ' + stock_code)\n",
    "        features = get_features(daily_price_data, stock_code, date_list, days)\n",
    "        stock_predictor_bot.sendMessage(chat_id, 'features generated for stock ' + stock_code)\n",
    "    except Exception as e:\n",
    "        stock_predictor_bot.sendMessage(chat_id, 'failed to generate features')\n",
    "        print('failed to generate features due to ' + str(e))\n",
    "        return\n",
    "    \n",
    "    try :\n",
    "        stock_predictor_bot.sendMessage(chat_id, 'predicting for stock ' + stock_code)\n",
    "        df = sc.parallelize([{'features':features[key], 'date':key} for key in features.keys()]).toDF()\n",
    "        list_to_vector_udf = udf(lambda l: Vectors.dense(l), VectorUDT())\n",
    "        final_data = df.select(df['date'], list_to_vector_udf(df[\"features\"]).alias(\"features\"))\n",
    "\n",
    "        predictions = gbtModel_30_features.transform(final_data)\n",
    "        predictions = predictions.select(\"prediction\", \"date\")\n",
    "        predictions = predictions.collect()\n",
    "        result = 'prediction result :\\n'\n",
    "        for p in predictions :\n",
    "            result = result + 'date ' + p['date'] + ' ' + str(round(p['prediction'], 4)) + '\\n'\n",
    "        stock_predictor_bot.sendMessage(chat_id, result)\n",
    "    except Exception as e :\n",
    "        traceback.print_exc()\n",
    "        print(\"exception when predict stock \" + str(e))\n",
    "    \n",
    "def start():\n",
    "    MessageLoop(stock_predictor_bot, handle_message).run_as_thread()\n",
    "    print ('Stock Predictor Bot Listening ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Predictor Bot Listening ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/threading.py\", line 862, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/telepot/loop.py\", line 148, in run_forever\n",
      "    self._bot.scheduler.run_as_thread()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/telepot/__init__.py\", line 404, in run_as_thread\n",
      "    self.daemon = True\n",
      "  File \"/usr/lib/python3.5/threading.py\", line 1139, in daemon\n",
      "    raise RuntimeError(\"cannot set daemon status of active thread\")\n",
      "RuntimeError: cannot set daemon status of active thread\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated 10\n",
      "date list ['8-Dec-17', '1-Nov-17', '3-Nov-17']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tryan/spark_tensor/spark-2.3.0-bin-hadoop2.7/python/pyspark/sql/session.py:360: UserWarning: Using RDD of dict to inferSchema is deprecated. Use pyspark.sql.Row instead\n",
      "  warnings.warn(\"Using RDD of dict to inferSchema is deprecated. \"\n"
     ]
    }
   ],
   "source": [
    "start()\n",
    "\n",
    "import time\n",
    "while 1:\n",
    "    time.sleep(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
