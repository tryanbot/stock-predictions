{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import telepot\n",
    "from telepot.loop import MessageLoop\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import threading\n",
    "import glob\n",
    "import re\n",
    "\n",
    "stock_predictor_bot = telepot.Bot('359528427:AAHKD8rIiFpo0ufZTDvLRGQ9c6gTfFFfYq4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "# logger = logging.getLogger()\n",
    "# logger.setLevel(logging.INFO)\n",
    "# from pyspark.sql import Row\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "sys.path.insert(0, spark_home + \"/python\")\n",
    "\n",
    "# Add the py4j to the path.\n",
    "# You may need to change the version number to match your install\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.6-src.zip'))\n",
    "\n",
    "# Initialize PySpark to predefine the SparkContext variable 'sc'\n",
    "exec(open(os.path.join(spark_home, 'python/pyspark/shell.py')).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import GBTRegressionModel\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_float( x):\n",
    "    try:\n",
    "        x['Close'] = float(x['Close'])\n",
    "        x['High'] = float(x['High'])\n",
    "        x['Low'] = float(x['Low'])\n",
    "        x['Open'] = float(x['Open'])\n",
    "        return x\n",
    "    except:\n",
    "        x['Close'] = float(x['Close'])\n",
    "        x['High'] = float(x['Close'])\n",
    "        x['Low'] = float(x['Close'])\n",
    "        x['Open'] = float(x['Close'])\n",
    "        return x\n",
    "    \n",
    "stock_data = pd.DataFrame()\n",
    "d_transformed = pd.DataFrame()\n",
    "days = 30\n",
    "\n",
    "def feature_ext(temp=None):\n",
    "    temp['close_close_gap'] = (temp['Close'].shift(-1) - temp['Close']) / temp['Close']\n",
    "    temp['close_open_gap'] = (temp['Open'].shift(-1) - temp['Close']) / temp['Close']\n",
    "    temp['close_high_gap'] = (temp['High'].shift(-1) - temp['Close']) / temp['Close']\n",
    "    temp['close_low_gap'] = (temp['Low'].shift(-1) - temp['Close']) / temp['Close']\n",
    "    temp.drop(labels=[\"High\",\"Low\",\"Open\",\"Close\", \"Volume\"], axis=1,inplace=True)\n",
    "    return temp\n",
    "\n",
    "list_stock = glob.glob('until31_2017/*.csv')\n",
    "all_stock = pd.DataFrame(columns=['stock_code','Date','close_open_gap','close_high_gap','close_low_gap','close_close_gap','Volume'])\n",
    "\n",
    "def get_feature(code, date, days_to_be_stacked=2) :\n",
    "    try :\n",
    "        df = pd.read_csv('until31_2017/' + code + '.csv')\n",
    "        selected_index = df.index[df['Date'] == '8-Dec-17'].tolist()\n",
    "        \n",
    "        if len(selected_index) == 0 :\n",
    "            return [];\n",
    "        \n",
    "        selected_index = selected_index[0]\n",
    "        df = df[selected_index + 1 : selected_index + days_to_be_stacked + 2]\n",
    "        df = df.reset_index().drop('index',axis=1)\n",
    "        df = df.drop(labels=['Date'], axis=1)\n",
    "        df = df.apply(lambda x:convert_float(x),axis=1)\n",
    "        feature_ext(df)\n",
    "        df = df[0:days_to_be_stacked]\n",
    "        df = df.stack().to_frame().T\n",
    "        df.columns = ['{}_{}'.format(*c) for c in df.columns]\n",
    "#         return df\n",
    "        return df.values[0];\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"exception when get feature \" + str(e))\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def handle_message(msg):\n",
    "    content_type, chat_type, chat_id = telepot.glance(msg)\n",
    "\n",
    "    message = \"\"\n",
    "    username = msg[\"from\"][\"first_name\"]\n",
    "    if content_type == 'text':\n",
    "        message = msg[\"text\"]\n",
    "        \n",
    "        if 'predict' in message :\n",
    "            stock_predictor_bot.sendMessage(chat_id, 'prediction starting.. ')\n",
    "            predict_stock(chat_id, message)\n",
    "\n",
    "def predict_stock(chat_id, msg):\n",
    "    try :\n",
    "        temp = msg.split(\" \")\n",
    "        stock_code = temp[1]\n",
    "        date = temp[2]\n",
    "        stock_predictor_bot.sendMessage(chat_id, 'gathering features for stock ' + stock_code)\n",
    "        feature = get_feature(stock_code, date)\n",
    "        \n",
    "        if len(feature) == 0 :\n",
    "            stock_predictor_bot.sendMessage(chat_id, 'invalid data')\n",
    "        \n",
    "        df = sc.parallelize([{'features':feature.tolist()}]).toDF()\n",
    "        list_to_vector_udf = udf(lambda l: Vectors.dense(l), VectorUDT())\n",
    "        final_data = df.select(list_to_vector_udf(df[\"features\"]).alias(\"features\"))\n",
    "        savedModel = PipelineModel.load('gbtModel_3_features')\n",
    "        \n",
    "        stock_predictor_bot.sendMessage(chat_id, 'predicting for stock ' + stock_code)\n",
    "        predictions = savedModel.transform(final_data)\n",
    "        result = round(predictions.collect()[0]['prediction'], 4)\n",
    "        stock_predictor_bot.sendMessage(chat_id, 'prediction result ' + str(result))\n",
    "    except Exception as e :\n",
    "        print(\"exception when predict stock \" + str(e))\n",
    "    \n",
    "def start():\n",
    "    MessageLoop(stock_predictor_bot, handle_message).run_as_thread()\n",
    "    print ('Stock Predictor Bot Listening ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/threading.py\", line 862, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/telepot/loop.py\", line 148, in run_forever\n",
      "    self._bot.scheduler.run_as_thread()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/telepot/__init__.py\", line 404, in run_as_thread\n",
      "    self.daemon = True\n",
      "  File \"/usr/lib/python3.5/threading.py\", line 1139, in daemon\n",
      "    raise RuntimeError(\"cannot set daemon status of active thread\")\n",
      "RuntimeError: cannot set daemon status of active thread\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Food Bot Listening ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tryan/spark_tensor/spark-2.3.0-bin-hadoop2.7/python/pyspark/sql/session.py:360: UserWarning: Using RDD of dict to inferSchema is deprecated. Use pyspark.sql.Row instead\n",
      "  warnings.warn(\"Using RDD of dict to inferSchema is deprecated. \"\n"
     ]
    }
   ],
   "source": [
    "start()\n",
    "\n",
    "import time\n",
    "while 1:\n",
    "    time.sleep(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
